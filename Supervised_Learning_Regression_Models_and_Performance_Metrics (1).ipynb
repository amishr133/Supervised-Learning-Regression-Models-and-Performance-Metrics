{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyLTGaqQa3wi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1) What is Simple Linear Regression (SLR)? Explain its purpose?\n",
        "\n",
        "- **Simple Linear Regression (SLR)** is a **statistical method** used to study the **relationship between two variables** — one **independent variable (X)** and one **dependent variable (Y)**.\n",
        "\n",
        "**Definition**\n",
        "\n",
        "Simple Linear Regression estimates how the dependent variable ( Y ) changes as the independent variable ( X ) changes.\n",
        "It fits a **straight line** (called the regression line) through the data points to predict ( Y ) based on ( X ).\n",
        "\n",
        "The equation for SLR is:\n",
        "\n",
        "[\n",
        "Y = β₀ + β₁X + ε\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( Y ) = Dependent variable (the one we’re trying to predict)\n",
        "* ( X ) = Independent variable (the predictor)\n",
        "* ( β₀ ) = Intercept (value of Y when X = 0)\n",
        "* ( β₁ ) = Slope (change in Y for each unit change in X)\n",
        "* ( ε ) = Error term (difference between predicted and actual value)\n",
        "\n",
        "**Purpose of Simple Linear Regression**\n",
        "\n",
        "1. **Prediction:**\n",
        "   To predict the value of one variable based on the value of another.\n",
        "   Example: Predicting **house price (Y)** based on **size (X)**.\n",
        "\n",
        "2. **Understanding relationships:**\n",
        "   To determine whether and how strongly two variables are related.\n",
        "   Example: Understanding the relationship between **advertising spend** and **sales**.\n",
        "\n",
        "3. **Trend analysis:**\n",
        "   To identify general trends in data — for instance, if sales increase linearly with marketing expenditure.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Suppose we have data on hours studied (X) and exam score (Y).\n",
        "If the regression line comes out as:\n",
        "\n",
        "[\n",
        "Y = 30 + 5X\n",
        "]\n",
        "\n",
        "This means:\n",
        "\n",
        "* Base score (when hours studied = 0) is 30.\n",
        "* For every additional hour studied, the score increases by 5 points.\n",
        "\n",
        "**Key Assumptions**\n",
        "\n",
        "1. Linear relationship between X and Y\n",
        "2. Independence of observations\n",
        "3. Constant variance of errors (homoscedasticity)\n",
        "4. Errors are normally distributed\n"
      ],
      "metadata": {
        "id": "sD6Pnkhga-Wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uX6uAPdpgdGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "- The **key assumptions of Simple Linear Regression (SLR)** ensure that the model’s results are **valid, reliable, and interpretable**.\n",
        "\n",
        "\n",
        "1. **Linearity**\n",
        "\n",
        "* The relationship between the **independent variable (X)** and the **dependent variable (Y)** is **linear**.\n",
        "* This means changes in ( Y ) are proportional to changes in ( X ).\n",
        "* **Check:** Scatter plot of X vs. Y should show a roughly straight-line pattern.\n",
        "\n",
        "*Example:* If doubling X roughly doubles Y, the relationship is likely linear.\n",
        "\n",
        "\n",
        "2. **Independence of Errors**\n",
        "\n",
        "* The **residuals (errors)** — the differences between actual and predicted Y — should be **independent** of each other.\n",
        "* No pattern or correlation should exist among errors.\n",
        "\n",
        "*Why it matters:* If errors are correlated (e.g., in time-series data), predictions can become biased.\n",
        "\n",
        "3. **Homoscedasticity (Constant Variance of Errors)**\n",
        "\n",
        "* The **variance of residuals** should be **constant** across all levels of X.\n",
        "* In other words, the spread of errors should be uniform along the regression line.\n",
        "\n",
        "*Check:* A plot of residuals vs. predicted values should show random scatter (no funnel shape).\n",
        "\n",
        "\n",
        "4. **Normality of Errors**\n",
        "\n",
        "* The residuals should be **normally distributed** around the regression line.\n",
        "* This assumption is especially important for hypothesis testing and constructing confidence intervals.\n",
        "\n",
        "*Check:* Histogram or Q-Q plot of residuals should look approximately normal.\n",
        "\n",
        "5. **No Measurement Error in X**\n",
        "\n",
        "* The independent variable (X) is assumed to be measured **without error**.\n",
        "* In practice, small measurement errors are okay, but large ones can distort the relationship.\n",
        "\n",
        "**Summary Table**\n",
        "\n",
        "| **Assumption**            | **Meaning**                                   | **How to Check**                  |\n",
        "| ------------------------- | --------------------------------------------- | --------------------------------- |\n",
        "| Linearity                 | Relationship between X and Y is straight-line | Scatter plot                      |\n",
        "| Independence of errors    | Residuals not correlated                      | Durbin–Watson test, residual plot |\n",
        "| Homoscedasticity          | Equal variance of errors                      | Residuals vs. fitted values plot  |\n",
        "| Normality of errors       | Errors are normally distributed               | Q-Q plot, histogram               |\n",
        "| No measurement error in X | X values are accurate                         | Data collection methods           |\n",
        "\n"
      ],
      "metadata": {
        "id": "hPUNPsaObib-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hBsbIH0geWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) Write the mathematical equation for a simple linear regression model and\n",
        "explain each term.?\n",
        "\n",
        "- **Equation:**\n",
        "\n",
        "[\n",
        "Y = β₀ + β₁X + ε\n",
        "]\n",
        "\n",
        "\n",
        "**Explanation of Each Term:**\n",
        "\n",
        "| **Term** | **Meaning**                   | **Description**                                                                                                                                         |\n",
        "| -------- | ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| ( Y )    | **Dependent Variable**        | The variable we want to predict or explain (e.g., sales, marks, salary).                                                                                |\n",
        "| ( X )    | **Independent Variable**      | The predictor or explanatory variable used to predict Y (e.g., advertising spend, hours studied, experience).                                           |\n",
        "| ( β₀ )   | **Intercept (Constant Term)** | The expected value of Y when X = 0. It represents where the regression line crosses the Y-axis.                                                         |\n",
        "| ( β₁ )   | **Slope Coefficient**         | The amount by which Y changes for a **one-unit increase** in X. It measures the strength and direction of the relationship between X and Y.             |\n",
        "| ( ε )    | **Error Term (Residual)**     | The difference between the **actual value** of Y and the **predicted value** from the model. It captures random variation or factors not included in X. |\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Suppose the regression equation is:\n",
        "[\n",
        "Y = 25 + 4X\n",
        "]\n",
        "\n",
        "This means:\n",
        "\n",
        "* Intercept ((β₀ = 25)): When X = 0, the predicted Y = 25.\n",
        "* Slope ((β₁ = 4)): For every 1-unit increase in X, Y increases by 4 units.\n",
        "\n",
        "*Example interpretation:*\n",
        "If X = hours studied and Y = exam score, then each additional hour studied increases the expected score by 4 marks.\n",
        "\n"
      ],
      "metadata": {
        "id": "qkFM5kTwcbrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IuYfs3Miggsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Provide a real-world example where simple linear regression can be\n",
        "applied.?\n",
        "\n",
        "- **Example: Predicting House Prices Based on Size**\n",
        "\n",
        "**Scenario:**\n",
        "A real estate analyst wants to predict the **price of a house (Y)** based on its **size in square feet (X)**.\n",
        "\n",
        "**Step 1: Define the Variables**\n",
        "\n",
        "* **Dependent Variable (Y):** House Price (in ₹ or $)\n",
        "* **Independent Variable (X):** House Size (in square feet)\n",
        "\n",
        "**Step 2: Model Equation**\n",
        "\n",
        "[\n",
        "\\text{Price} = β₀ + β₁(\\text{Size}) + ε\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( β₀ ): Base price (price when size = 0, often theoretical)\n",
        "* ( β₁ ): Price increase per additional square foot\n",
        "* ( ε ): Error term (factors like location, condition, etc.)\n",
        "\n",
        "**Step 3: Example Outcome**\n",
        "\n",
        "Suppose after fitting the regression model, we get:\n",
        "[\n",
        "\\text{Price} = 5,00,000 + 3,000 \\times (\\text{Size})\n",
        "]\n",
        "\n",
        "This means:\n",
        "\n",
        "* The base price of any property (intercept) = ₹5,00,000\n",
        "* For every additional **1 sq. ft.**, the price increases by **₹3,000**\n",
        "\n",
        "**Step 4: Prediction Example**\n",
        "\n",
        "If a house is **1,200 sq. ft**, then:\n",
        "[\n",
        "\\text{Predicted Price} = 5,00,000 + 3,000(1,200) = ₹41,00,000\n",
        "]\n",
        "\n",
        "**Why Use SLR Here**\n",
        "\n",
        "* The relationship between **size** and **price** is approximately **linear**.\n",
        "* It helps in **estimating market prices** and **making investment decisions**.\n",
        "\n",
        "**Other Real-World Examples**\n",
        "\n",
        "| **Scenario**               | **Dependent Variable (Y)** | **Independent Variable (X)** |\n",
        "| -------------------------- | -------------------------- | ---------------------------- |\n",
        "| Predicting student scores  | Exam Marks                 | Hours Studied                |\n",
        "| Predicting sales           | Monthly Sales              | Advertising Budget           |\n",
        "| Predicting crop yield      | Yield (kg)                 | Rainfall (mm)                |\n",
        "| Predicting fuel efficiency | Mileage (km/l)             | Engine Size (cc)             |\n",
        "\n"
      ],
      "metadata": {
        "id": "BibJGkdYdKQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nhH-L4k5giE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) What is the method of least squares in linear regression?\n",
        "\n",
        "- The **Method of Least Squares** is the **most common technique** used to find the **best-fitting line** in a **linear regression model** — that is, the line that best represents the relationship between the independent variable (X) and the dependent variable (Y).\n",
        "\n",
        "**Definition**\n",
        "\n",
        "The **method of least squares** determines the regression line by **minimizing the sum of the squared differences** between the **actual values (Y)** and the **predicted values (( \\hat{Y} ))** from the line.\n",
        "\n",
        "In simple terms:\n",
        "It finds the line where the total error between the observed and predicted points is **as small as possible**.\n",
        "\n",
        "**Mathematical Idea**\n",
        "\n",
        "For each data point ( (X_i, Y_i) ), the model predicts:\n",
        "[\n",
        "\\hat{Y_i} = β₀ + β₁X_i\n",
        "]\n",
        "\n",
        "The **residual (error)** for each point is:\n",
        "[\n",
        "e_i = Y_i - \\hat{Y_i}\n",
        "]\n",
        "\n",
        "The **method of least squares** minimizes the **sum of squared residuals (errors):**\n",
        "[\n",
        "S = \\sum (Y_i - \\hat{Y_i})^2 = \\sum (Y_i - β₀ - β₁X_i)^2\n",
        "]\n",
        "\n",
        "We find ( β₀ ) and ( β₁ ) such that ( S ) is **as small as possible**.\n",
        "\n",
        "**Formulas for Coefficients**\n",
        "\n",
        "By minimizing ( S ), we derive the formulas:\n",
        "\n",
        "[\n",
        "β₁ = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum (X_i - \\bar{X})^2}\n",
        "]\n",
        "\n",
        "[\n",
        "β₀ = \\bar{Y} - β₁\\bar{X}\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( \\bar{X} ) = Mean of X values\n",
        "* ( \\bar{Y} ) = Mean of Y values\n",
        "\n",
        "**Purpose**\n",
        "\n",
        "* To **find the most accurate regression line** that minimizes overall prediction error.\n",
        "* To ensure the line fits the data in a way that the squared deviations between observed and predicted values are minimized.\n",
        "\n",
        "**Example**\n",
        "\n",
        "If we have data on:\n",
        "\n",
        "| X (Hours studied) | Y (Marks scored) |\n",
        "| ----------------- | ---------------- |\n",
        "| 2                 | 40               |\n",
        "| 3                 | 50               |\n",
        "| 4                 | 65               |\n",
        "| 5                 | 70               |\n",
        "\n",
        "Using the least squares method, we can calculate β₀ and β₁ to get the best-fitting line:\n",
        "[\n",
        "Y = β₀ + β₁X\n",
        "]\n",
        "\n",
        "That line could look like:\n",
        "[\n",
        "Y = 25 + 9X\n",
        "]\n",
        "→ Predicts that each extra hour of study increases the score by 9 marks.\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "| **Concept**   | **Meaning**                                               |\n",
        "| ------------- | --------------------------------------------------------- |\n",
        "| Objective     | Minimize total squared prediction errors                  |\n",
        "| What it finds | Best-fitting regression line                              |\n",
        "| Why squares?  | Squaring avoids negative errors canceling positive ones   |\n",
        "| Result        | Provides optimal values for intercept (β₀) and slope (β₁) |\n",
        "\n"
      ],
      "metadata": {
        "id": "p47IGy9Idv8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "23DllXVAgauz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "- **Logistic Regression — Overview**\n",
        "\n",
        "**Logistic Regression** is a **statistical method** used to model the relationship between one or more independent variables (X) and a **categorical dependent variable (Y)** — usually **binary** (i.e., having two possible outcomes like *Yes/No*, *0/1*, *Success/Failure*).\n",
        "\n",
        "Despite its name, **it’s a classification technique, not a regression technique**.\n",
        "\n",
        "**Purpose**\n",
        "\n",
        "To **predict the probability** that a given input belongs to a particular class.\n",
        "For example:\n",
        "\n",
        "* Will a customer **buy** a product? (Yes/No)\n",
        "* Will a student **pass** or **fail** an exam?\n",
        "* Is an email **spam** or **not spam**?\n",
        "\n",
        "**Mathematical Form**\n",
        "\n",
        "Instead of predicting a continuous value (like Linear Regression), Logistic Regression predicts a **probability** between 0 and 1 using the **logistic (sigmoid) function**:\n",
        "\n",
        "[\n",
        "P(Y=1) = \\frac{1}{1 + e^{-(β₀ + β₁X)}}\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( P(Y=1) ): Probability that the output is 1 (success)\n",
        "* ( β₀, β₁ ): Coefficients estimated from data\n",
        "* ( e ): Base of natural logarithms (~2.718)\n",
        "\n",
        "**Interpretation**\n",
        "\n",
        "* If ( P(Y=1) > 0.5 ), predict **class = 1**\n",
        "* If ( P(Y=1) < 0.5 ), predict **class = 0**\n",
        "\n",
        "**Key Differences Between Linear and Logistic Regression**\n",
        "\n",
        "| **Feature**              | **Linear Regression**                         | **Logistic Regression**                                       |\n",
        "| ------------------------ | --------------------------------------------- | ------------------------------------------------------------- |\n",
        "| **Type of Output**       | Continuous (any real number)                  | Categorical (usually binary: 0/1)                             |\n",
        "| **Goal**                 | Predict a numeric value (e.g., sales, salary) | Predict a probability or class (e.g., yes/no)                 |\n",
        "| **Equation Form**        | ( Y = β₀ + β₁X + ε )                          | ( P(Y=1) = \\frac{1}{1 + e^{-(β₀ + β₁X)}} )                    |\n",
        "| **Linearity Assumption** | Assumes a linear relationship between X and Y | Assumes a linear relationship between X and **log-odds of Y** |\n",
        "| **Error Distribution**   | Errors are normally distributed               | Follows a binomial distribution                               |\n",
        "| **Use Case**             | Regression (continuous prediction)            | Classification (categorical prediction)                       |\n",
        "| **Range of Output**      | (−∞ to +∞)                                    | (0 to 1) — represents probability                             |\n",
        "\n",
        "**Example**\n",
        "\n",
        "| Hours Studied (X) | Pass (Y) |\n",
        "| ----------------- | -------- |\n",
        "| 1                 | 0        |\n",
        "| 3                 | 0        |\n",
        "| 4                 | 1        |\n",
        "| 6                 | 1        |\n",
        "| 8                 | 1        |\n",
        "\n",
        "* **Linear Regression** might try to fit a straight line (and can predict impossible values like −0.2 or 1.3).\n",
        "* **Logistic Regression** fits an **S-shaped (sigmoid) curve** and gives probabilities like:\n",
        "\n",
        "  * ( P(\\text{Pass}) = 0.1, 0.3, 0.6, 0.9, ) etc.\n",
        "\n",
        "**In short:**\n",
        "\n",
        "> **Linear Regression** → Predicts a *continuous value*\n",
        "\n",
        "> **Logistic Regression** → Predicts a *probability of belonging to a category*\n",
        "\n"
      ],
      "metadata": {
        "id": "fB_mF5YVea9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X5tshqIkgliF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Name and briefly describe three common evaluation metrics for regression\n",
        "models?\n",
        "\n",
        "- **1. Mean Absolute Error (MAE)**\n",
        "\n",
        "**Definition:**\n",
        "MAE measures the **average absolute difference** between the actual and predicted values.\n",
        "\n",
        "[\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - \\hat{Y_i}|\n",
        "]\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* It tells how far predictions are, on average, from the actual values.\n",
        "* Lower MAE = better accuracy.\n",
        "* Easy to understand because it’s in the same unit as the target variable.\n",
        "\n",
        "*Example:*\n",
        "If MAE = 5, the model’s predictions are off by 5 units on average.\n",
        "\n",
        "**2. Mean Squared Error (MSE)**\n",
        "\n",
        "**Definition:**\n",
        "MSE measures the **average of squared differences** between actual and predicted values.\n",
        "\n",
        "[\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y_i})^2\n",
        "]\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* Penalizes **larger errors more strongly** because errors are squared.\n",
        "* Useful for emphasizing big mistakes.\n",
        "* Lower MSE = better model performance.\n",
        "\n",
        "*Note:* Units are **squared**, so not directly interpretable in original scale.\n",
        "\n",
        "**3. R-squared (R²) – Coefficient of Determination**\n",
        "\n",
        "**Definition:**\n",
        "R² represents the **proportion of variance in the dependent variable (Y)** that is explained by the independent variable(s) in the model.\n",
        "\n",
        "[\n",
        "R^2 = 1 - \\frac{\\sum (Y_i - \\hat{Y_i})^2}{\\sum (Y_i - \\bar{Y})^2}\n",
        "]\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* ( R^2 = 1 ): Perfect prediction\n",
        "* ( R^2 = 0 ): Model explains none of the variance\n",
        "* Higher R² = better model fit\n",
        "\n",
        "*Example:*\n",
        "If ( R^2 = 0.85 ), it means **85% of the variation** in Y is explained by the model.\n",
        "\n",
        "**Summary Table**\n",
        "\n",
        "| **Metric** | **Formula**                             | **Interpretation**                                 |   |                                           |\n",
        "| ---------- | --------------------------------------- | -------------------------------------------------- | - | ----------------------------------------- |\n",
        "| **MAE**    | ( \\frac{1}{n}\\sum                       | Y_i - \\hat{Y_i}                                    | ) | Average absolute error; easy to interpret |\n",
        "| **MSE**    | ( \\frac{1}{n}\\sum (Y_i - \\hat{Y_i})^2 ) | Penalizes large errors; sensitive to outliers      |   |                                           |\n",
        "| **R²**     | ( 1 - \\frac{SS_{res}}{SS_{tot}} )       | Measures proportion of variance explained by model |   |                                           |\n",
        "\n"
      ],
      "metadata": {
        "id": "shCIqO7be_6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iETRURWCgnfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "- **Purpose of the R-squared (R²) Metric in Regression Analysis**\n",
        "\n",
        "**R-squared (R²)** — also called the **coefficient of determination** — is a statistical measure that explains **how well a regression model fits the data**.\n",
        "\n",
        "**Definition**\n",
        "\n",
        "R² represents the **proportion of the variance** in the **dependent variable (Y)** that is **explained by the independent variable(s) (X)** in the model.\n",
        "\n",
        "[\n",
        "R^2 = 1 - \\frac{\\text{SS}*{res}}{\\text{SS}*{tot}}\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* ( \\text{SS}_{res} = \\sum (Y_i - \\hat{Y_i})^2 ) → Residual sum of squares (unexplained variance)\n",
        "* ( \\text{SS}_{tot} = \\sum (Y_i - \\bar{Y})^2 ) → Total sum of squares (total variance in Y)\n",
        "\n",
        "**Purpose**\n",
        "\n",
        "1. **Measures Goodness of Fit**\n",
        "   R² shows how well the regression line represents the actual data points.\n",
        "\n",
        "   * The closer R² is to **1**, the better the model fits the data.\n",
        "   * An R² of **0** means the model does not explain any variation in Y.\n",
        "\n",
        "2. **Explains Variance**\n",
        "   It quantifies the percentage of the dependent variable’s variation that is explained by the independent variable(s).\n",
        "\n",
        "   * Example: ( R^2 = 0.80 ) → 80% of the variation in Y is explained by X; 20% is due to other factors or random noise.\n",
        "\n",
        "3. **Model Comparison**\n",
        "   Helps compare models — higher R² generally means a better fit (but should be used carefully with multiple predictors, as R² always increases when more variables are added).\n",
        "\n",
        "**Interpretation Example**\n",
        "\n",
        "If you’re predicting **house prices** based on **size**, and your model gives:\n",
        "[\n",
        "R^2 = 0.90\n",
        "]\n",
        "→ It means **90% of the variation** in house prices can be explained by house size.\n",
        "Only **10%** of the variation is due to other factors (like location, age, etc.).\n",
        "\n",
        "**Important Notes**\n",
        "\n",
        "* R² alone **does not indicate** if the model is good or if it makes **accurate predictions** — a high R² can still come from an overfitted model.\n",
        "* For multiple regression, we often use **Adjusted R²**, which accounts for the number of predictors.\n",
        "\n",
        "**In summary:**\n",
        "\n",
        "> **R² measures how much of the variation in the dependent variable is explained by the model — helping you judge how well your regression line fits the data.**\n"
      ],
      "metadata": {
        "id": "3X7lEBQPfmra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fmbZ-5j_goty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "# X: independent variable (e.g., hours studied)\n",
        "# Y: dependent variable (e.g., exam score)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # reshaped to 2D array for sklearn\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Print slope (coefficient) and intercept\n",
        "print(\"Slope (β₁):\", model.coef_[0])\n",
        "print(\"Intercept (β₀):\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mxA_DGJgDWp",
        "outputId": "36975b69-08f4-4901-ee5e-0486f9752fd3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (β₁): 0.6\n",
            "Intercept (β₀): 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCLsJj7ygPsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}